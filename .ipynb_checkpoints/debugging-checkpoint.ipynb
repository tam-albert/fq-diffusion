{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008e6fa3-7853-4436-84e8-7855eba4556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/env/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/user/mambaforge/envs/env/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/user/mambaforge/envs/env/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import flatquant.utils as utils\n",
    "import flatquant.args_utils as args_utils\n",
    "import flatquant.model_utils as model_utils\n",
    "import flatquant.data_utils as data_utils\n",
    "import flatquant.eval_utils as eval_utils\n",
    "import flatquant.train_utils as train_utils\n",
    "import flatquant.flat_utils as flat_utils\n",
    "import gptq_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f03795-c5de-496b-bf0b-77139078a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.seed_everything(seed=args.seed)\n",
    "# 1. prepare calibration data\n",
    "if args.cali_trans or args.add_diag or args.lwc or args.lac:\n",
    "    calibration_data = train_utils.prepare_calibration_data(args, pipe, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea74a2d-878d-4492-834f-ff4579e2f709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/env/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c630c25a0834811bdfa13ab42fa7380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934e940fcba44b6a908d03bdad80a6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0-27): 28 x BasicTransformerBlock(\n",
      "    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=False)\n",
      "    (attn1): Attention(\n",
      "      (to_q): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "      (to_k): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "      (to_v): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "      (to_out): ModuleList(\n",
      "        (0): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=False)\n",
      "    (attn2): Attention(\n",
      "      (to_q): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "      (to_k): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "      (to_v): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "      (to_out): ModuleList(\n",
      "        (0): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (ff): FeedForward(\n",
      "      (net): ModuleList(\n",
      "        (0): GELU(\n",
      "          (proj): Linear(in_features=1152, out_features=4608, bias=True)\n",
      "        )\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Linear(in_features=4608, out_features=1152, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pipe, apply_flatquant_to_model = model_utils.get_model(args.model)\n",
    "pipe.to(utils.DEV)\n",
    "\n",
    "model = pipe.transformer\n",
    "\n",
    "print(model.transformer_blocks)\n",
    "\n",
    "# get calibration data\n",
    "data = data_utils.get_loaders(\n",
    "    args,\n",
    "    args.cali_dataset,\n",
    "    nsamples=args.nsamples,\n",
    "    seed=args.seed,\n",
    "    eval_mode=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d370367-7640-421a-bf77-9cf5278a1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "args = argparse.Namespace(model='./modelzoo/pixart-sigma/PixArt-Sigma-XL-2-1024-MS', seed=0, a_bits=4, a_groupsize=-1, a_asym=False, w_bits=4, w_groupsize=-1, w_asym=False, gptq=False, gptq_mse=False, percdamp=0.01, act_order=False, epochs=15, cali_dataset='coco', nsamples=4, cali_bsz=4, cali_timesteps=10, flat_lr=0.005, cali_trans=True, add_diag=True, lwc=True, lac=True, resume=False, save_matrix=True, reload_matrix=False, matrix_path=None, diag_init='sq_style', diag_alpha=0.3, warmup=False, deactive_amp=False, direct_inv=False, separate_vtrans=False, q_bits=16, q_asym=False, q_groupsize=-1, k_bits=4, k_asym=True, k_groupsize=128, v_bits=4, v_asym=True, v_groupsize=128, output_dir='./outputs', exp_name='exp', lm_eval=False, tasks=['piqa', 'hellaswag', 'arc_easy', 'arc_challenge', 'winogrande', 'lambada_openai'], lm_eval_batch_size=128, distribute_model=False, quantize=True, cache_dir='./outputs/.cache', model_name='PixArt-Sigma-XL-2-1024-MS', exp_dir='./outputs/PixArt-Sigma-XL-2-1024-MS/w4a4/exp')\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the logging level\n",
    "logger.setLevel(logging.INFO)  # or DEBUG, WARNING, ERROR, etc.\n",
    "\n",
    "# Create a console handler\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16471b2-4718-4d29-940c-29a7f08ea9d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FlatQuantPixArtFeedForward' object has no attribute 'net'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mtransformer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 2. replace linear/attention layers with special FlatQuant layers\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m pipe\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m \u001b[43mapply_flatquant_to_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished applying FlatQuant to model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mresume:\n",
      "File \u001b[0;32m~/fq-diffusion/flatquant/model_tools/pixart_utils.py:461\u001b[0m, in \u001b[0;36mapply_flatquant_to_pixart\u001b[0;34m(args, model)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_trans \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_trans\u001b[38;5;241m.\u001b[39mto_eval_mode()    \n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_flatquant_to_pixart\u001b[39m(args, model):\n\u001b[1;32m    462\u001b[0m     skip_initialization()\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# feedforward\u001b[39;00m\n",
      "File \u001b[0;32m~/fq-diffusion/flatquant/model_tools/pixart_utils.py:24\u001b[0m, in \u001b[0;36mFlatQuantPixArtFeedForward.__init__\u001b[0;34m(self, args, module)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# i actually dgaf\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m up_proj \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mproj\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# there is a gelu (tanh approximation) in the middle\u001b[39;00m\n\u001b[1;32m     26\u001b[0m down_proj \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mnet[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FlatQuantPixArtFeedForward' object has no attribute 'net'"
     ]
    }
   ],
   "source": [
    "model = pipe.transformer\n",
    "# 2. replace linear/attention layers with special FlatQuant layers\n",
    "pipe.transformer = apply_flatquant_to_model(args, pipe.transformer)\n",
    "logging.info(\"Finished applying FlatQuant to model.\")\n",
    "\n",
    "if args.resume:\n",
    "    flat_utils.load_flat_parameters(args, model)\n",
    "elif args.reload_matrix:\n",
    "    flat_utils.load_flat_matrices(args, model, path=args.matrix_path)\n",
    "elif args.cali_trans or args.add_diag or args.lwc or args.lac:\n",
    "    # 2. calibrate FlatQuant layers (learn affine transforms)\n",
    "    train_utils.cali_flat_quant(\n",
    "        args, pipe, calibration_data, utils.DEV, logger=logger\n",
    "    )\n",
    "if args.save_matrix and not args.reload_matrix:\n",
    "    flat_utils.save_flat_matrices(args, model)\n",
    "flat_utils.reparameterize_model(model)\n",
    "logging.info(\"Finished reparameterize model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c25e1b-8ec7-43af-9b75-21d924a5f7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
